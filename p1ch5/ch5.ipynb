{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input, w, b):\n",
    "    return w * input + b\n",
    "\n",
    "def lossFn(y_pred, y_test):\n",
    "    return ((y_test-y_pred)**2).mean()\n",
    "\n",
    "def gradFn(x, y, w, b):\n",
    "\n",
    "    y_pred = model(x,w,b)\n",
    "\n",
    "    dw = 2 * (y_pred-y) * x / y_pred.size(0)\n",
    "    db = 2 * (y_pred-y) * 1 / y_pred.size(0)\n",
    "\n",
    "    return torch.stack([dw.sum(), db.sum()])\n",
    "\n",
    "\n",
    "def training_loop_manual(n_epochs, learning_rate, params, t_u, t_c):\n",
    "\n",
    "    loss_mat=[]\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        if epoch==30:\n",
    "            learning_rate*=0.5\n",
    "        elif epoch==60:\n",
    "            learning_rate*=0.5\n",
    "\n",
    "        w, b = params\n",
    "\n",
    "        t_p = model(t_u, *params)\n",
    "\n",
    "        loss = lossFn(t_p, t_c)\n",
    "\n",
    "        grad = gradFn(t_u, t_c,params)\n",
    "        \n",
    "        loss_mat.append(loss)\n",
    "        params = params - learning_rate * grad\n",
    "        print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "\n",
    "    return params, loss_mat\n",
    "\n",
    "\n",
    "def training_loop_grad(n_epochs, learning_rate, params, t_u, t_c):\n",
    "\n",
    "    loss_mat=[]\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "\n",
    "        if epoch==30:\n",
    "            learning_rate*=0.5\n",
    "        elif epoch==60:\n",
    "            learning_rate*=0.5\n",
    "\n",
    "        loss = lossFn(model(t_u, *params), t_c)\n",
    "        loss.backward()\n",
    "\n",
    "        # print(loss.item())\n",
    "\n",
    "        loss_mat.append(loss.item())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            params -= learning_rate * params.grad\n",
    "            \n",
    "        print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "\n",
    "    return params, loss_mat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "lr = 1e-1\n",
    "# print(params.requires_grad)\n",
    "t_u2 = (t_u - t_u.mean()) / t_u.std()\n",
    "\n",
    "if not params.requires_grad:\n",
    "    params, loss_mat = training_loop_manual(\n",
    "        n_epochs = 100,\n",
    "        learning_rate = lr,\n",
    "        params = params,\n",
    "        t_u = t_u2,\n",
    "        t_c = t_c,\n",
    "    )\n",
    "else:\n",
    "    params, loss_mat = training_loop_grad(\n",
    "        n_epochs = 100,\n",
    "        learning_rate = lr,\n",
    "        params = params,\n",
    "        t_u = t_u2,\n",
    "        t_c = t_c,\n",
    "    )\n",
    "    pass\n",
    "\n",
    "plt.plot(loss_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "lr = 1e-1\n",
    "optimiser = optim.SGD([params], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    t_p = model(t_u2, *params)\n",
    "    loss = lossFn(t_p, t_c)\n",
    "\n",
    "    optimiser.zero_grad() # initialise optimiser gradient SUM = 0\n",
    "\n",
    "    loss.backward() # run the backward loop\n",
    "    optimiser.step() # step the optimiser based on the current grad and lr \n",
    "\n",
    "    print('Epoch %d, Loss %f' % (epoch+1, float(loss)))\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  7, 10,  1,  6,  9,  3,  2,  4,  8,  5]),\n",
       " tensor([ 0,  7, 10,  1,  6,  9,  3,  2,  4]),\n",
       " tensor([8, 5]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:] # -val_index to end\n",
    "\n",
    "shuffled_indices, train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_t_u = t_u[val_indices]\n",
    "val_t_c = t_c[val_indices]\n",
    "\n",
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "\n",
    "train_t_un = (train_t_u - train_t_u.mean()) / train_t_u.std()\n",
    "val_t_un = (val_t_u - val_t_u.mean()) / val_t_u.std()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_t_p = model(train_t_u, *params)\n",
    "    train_loss = lossFn(train_t_p, train_t_u)\n",
    "\n",
    "    val_t_p = model(val_t_u, *params)\n",
    "    val_loss = lossFn(val_t_p, val_t_c)\n",
    "\n",
    "    optimiser.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd2c030c20d18997dd039200e9575a3bf4a2bfb21637339c49d8f9344be1b631"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('DL38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
